<p align="left" width="100%">
  <img style="width:30%;align:left" src="img/logo-ait.png">             
</p>

# MSR Voice Input, Group 3
#### Kunaal Sikka, Mina Huh, Vu Nguyen, Nicolas Carmody, Jonas Bokstaller

## Project description and customer needs

Users often have a hard time knowing what voice commands are available and when. There are also issues with receiving feedback from the device on whether a command was heard or interpreted properly. The goal of our project is to develop guidelines for developers to follow so that their Hololens application integrates voice commands effectively and their target audience can use the commands with ease.

Link to [User Personas](https://docs.google.com/document/d/19S1B5Kuxh-lI8tsHfoAEIIXfTWTcwt1xHbvo8nMF6qo/edit?usp=sharing)

Meeting notes available upon request

## Ideas

We started by creating an [affinity cluster](https://drive.google.com/open?id=1M1NF_fIWtZ3Zx_IkFPaNNmv98yLZldGE) and openly sharing our ideas on how to improve the voice recognition experience on Hololens.

After this process, we came up with a rough list of requirements based on our affinity cluster and the user personas:
1. Teaching the user
    1. a tutorial
    3. examples
    4. help menu (easy to access)
2. Commands
    1. fluid understanding
    6. intuitive and recallable
    9. optimize commands that are frequently used
3. Feedback
    1. status - fail/disconnected/confirmation
    11. specific feedback
    12. suggestions 
4. UX
    1. same interface for all commands
    18. should not interfere with users field of view too much

Keeping in mind what we had learned in class about User Centered Design, we went out to optimize the Hololens experience so that users could more effectively engage with voice functions. We wanted to create a unified experience that would work across multiple scenarios. Our goal was to increase the utilization of voice commands in such a way that users could complete everday tasks more quickly and with ease. 

An evaluation of the history of introducing new interaction devices (in particular, the mouse and GUI) led us to believe that a great way to get users more comfortable with voice input would be to have them play a game. In addition, we set out to create a way for users to learn the game's commands easily and effectively using a virtual assistant. In this way we would also lessen the learning curve for users unfamiliar with the voice commands available in the game. Thus we came up with the following goals:

1. Portray the system as a character to make users feel comfortable engaging with it via voice
1. Teach users application specific voice commands with a game
1. Have the users complete a basic task (like send an email) and compare mouse usage with voice usage

View our presentation introducing our User Study to our stakeholders [here](https://drive.google.com/file/d/1ktx7gp4W8LCk07orwoCCEVg4L9FhZpza/view?usp=sharing).

After feedback from our stakeholder, we created our user study to test the effectiveness of a character that introduces application specific voice commands. Read more in our [Study Report](/Deliverables/Study_Report.pdf).

Also, see our User Study Presentation which discusses some of our findings [here](https://docs.google.com/presentation/d/1REDcLO9AXraoLu25bvrJDuQPfqy_d8A31S-66P3FSSM/edit?usp=sharing).
    
## Evaluation
Deliverables:

[Study Report](/Deliverables/Study_Report.pdf)

[User Study Presentation](/Deliverables/User_Study_presentation.pdf)

Describe your approach for evaluating your low-fi prototypes, present your results and your conclusion. 

Upload the document shared with the stakeholder to the "deliverables" folder and include the link here.

Optional: in this part you can also document the prototyping process: show different iterations, as well as failed ideas (Weeks 6-10)

## Final solution
    TODO
Describe your final solution to the problem and the prototype you developed in more detail here.
Upload your video to the "deliverables" folder and include the link here. 

(Weeks 10-14)
